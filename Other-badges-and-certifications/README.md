<h1 align="center"><a href="https://www.youracclaim.com/badges/6b21b1b0-e8f0-4c74-b8d0-639fe2d5a39d/public_url">Big Data Foundations - Level 2</a></h1>

<p align="center">
<img src="https://github.com/ntnnitinkr/courses-certifications/blob/master/Other-badges-and-certifications/Big%2BData%2BFound%2BLevel%2B2%2B-%2BCC%2Bv2.png" width="20%" height="20%">
</p>

<h2 align="center">About the Course</h2>
This badge earner understands the big data ecosystem and hadoop commands and operations to work with big data. The earner also has foundational knowledge around Spark and its operations including RDDs, DataFrames, and the various libraries associated with the Spark Core (MLlib, Spark SQL, Spark Streaming, GraphX).




<h1 align="center"><a href="https://www.youracclaim.com/badges/3ce9a615-69fc-4315-bdcc-f12d34a4efbe/public_url">Big Data Foundations - Level 1</a></h1>

<p align="center">
<img src="https://github.com/ntnnitinkr/courses-certifications/blob/master/Other-badges-and-certifications/Big%2BData%2BFound%2BLevel%2B1%2B-%2BCC%2B-%2B2019.png" width="20%" height="20%">
</p>

<h2 align="center">About the Course</h2>
This badge earner has a basic understanding of Big Data concepts and their applications to gain insight for providing better service to customers. The earner understands that Big Data should be processed in a platform that can handle the variety, velocity, and the volume of data by using components that require integration and data governance.




<h1 align="center"><a href="https://www.youracclaim.com/badges/8a88aba2-bfef-4acb-ab3e-17ce9472e658/public_url">Hadoop Programming - Level 1</a></h1>

<p align="center">
<img src="https://github.com/ntnnitinkr/courses-certifications/blob/master/Other-badges-and-certifications/Hadoop%2BProgramming%2BLevel%2B1%2B-%2BCC%2B-%2B2019.png" width="20%" height="20%">
</p>

<h2 align="center">About the Course</h2>
The badge earner demonstrates the ability to use programming concepts provided by the various technologies in the Hadoop ecosystem including, but not limited to MapReduce.




<h1 align="center"><a href="https://www.youracclaim.com/badges/e1e5ccb9-af5e-410c-9974-ce37862da223/public_url">Hadoop Foundations - Level 1</a></h1>

<p align="center">
<img src="https://github.com/ntnnitinkr/courses-certifications/blob/master/Other-badges-and-certifications/Hadoop%2BData%2BFound%2BLevel%2B1%2B-%2BCC%2B-%2B2019.png" width="20%" height="20%">
</p>

<h2 align="center">About the Course</h2>
This badge earner has a basic understanding of Hadoop. The earner can describe what Big Data is and the need for Hadoop to be able to process that data in a timely manner. The individual can describe the Hadoop architecture and how to work with the Hadoop Distributed File System (HDFS) using IBM BigInsights.




<h1 align="center"><a href="https://www.youracclaim.com/badges/ff67e681-e6de-466a-8b31-a91d86c6f3a8/public_url">Spark - Level 1</a></h1>

<p align="center">
<img src="https://github.com/ntnnitinkr/courses-certifications/blob/master/Other-badges-and-certifications/Spark%2BLevel%2B1%2Bver%2B2%2B-%2BCC%2B-%2B2019.png" width="20%" height="20%">
</p>

<h2 align="center">About the Course</h2>
This badge earner has a basic understanding of Spark. The earner can describe Spark, articulate its benefits, and describe how it is used. The individual can also use Resilient Distributed Datasets (RDD) and DataFrames to perform in-memory computing and create applications on top of the Spark built-in libraries.




<h1 align="center"><a href="https://www.youracclaim.com/badges/ff67e681-e6de-466a-8b31-a91d86c6f3a8/public_url">Spark - Level 1</a></h1>

<p align="center">
<img src="https://github.com/ntnnitinkr/courses-certifications/blob/master/Other-badges-and-certifications/Spark%2BLevel%2B1%2Bver%2B2%2B-%2BCC%2B-%2B2019.png" width="20%" height="20%">
</p>

<h2 align="center">About the Course</h2>
This badge earner has a basic understanding of Spark. The earner can describe Spark, articulate its benefits, and describe how it is used. The individual can also use Resilient Distributed Datasets (RDD) and DataFrames to perform in-memory computing and create applications on top of the Spark built-in libraries.
